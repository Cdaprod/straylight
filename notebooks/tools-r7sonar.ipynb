{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special thank you to Evan Perotti for the awesome walkthrough for querying project Sonar FDNS and the query code within the Lambda APIs!\n",
    "\n",
    "### Additionally, thank you to Rapid7 for the availability of this valuable dataset (https://www.rapid7.com/research/project-sonar/) and the blog post detailing how to build and query the dataset.\n",
    "\n",
    "### The following steps are adapted from the tutorials at: http://securityriskadvisors.com/blog/creating-a-project-sonar-fdns-api-with-aws/\n",
    "https://blog.rapid7.com/2018/10/16/how-to-conduct-dns-reconnaissance-for-02-using-rapid7-open-data-and-aws/\n",
    "\n",
    "\n",
    "### This notebook will take a domain name (i.e. microsoft.com) as input and query the project Sonar public dataset for the applicable DNS entries. Additionally, it processes the results by geomapping the IP addresses and producing a heatmap of the global external presence of the domain.\n",
    "\n",
    "### The results provide a completely passive method for reconnaisance and mapping of domains without any direct interaction, querying, or brute-forcing of a domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this notebook to work, AWS Athena needs to be manually configured using the following setup information. The queries and approach are from Rapid 7's blog detailing the process (https://blog.rapid7.com/2018/10/16/how-to-conduct-dns-reconnaissance-for-02-using-rapid7-open-data-and-aws/).\n",
    "\n",
    "\n",
    "### Within the Athena interface, you will need to run the following three queries to configure the environment:\n",
    "\n",
    "#### Query 1:\n",
    "CREATE DATABASE rapid7fdns;\n",
    "\n",
    "#### Query 2:\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS rapid7_fdns_any (\n",
    "  `timestamp` timestamp,\n",
    "  `name` string,\n",
    "  `type` string,\n",
    "  `value` string \n",
    ") PARTITIONED BY (\n",
    "  date string \n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "WITH SERDEPROPERTIES (\n",
    "  'serialization.format' = '1'\n",
    ") LOCATION 's3://rapid7-opendata/fdns/any/v1/'\n",
    "TBLPROPERTIES ('has_encrypted_data'='false');\n",
    "\n",
    "#### Query 3:\n",
    "msck repair table rapid7_fdns_any;\n",
    "\n",
    "#### Todo: codify the commands and dependencies into Boto3 commands to run directly from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not necessary to run but are helpful S3 queries to check for latest datasets\n",
    "#! aws s3 ls s3://rapid7-opendata/fdns/any/v1/ --no-sign-request\n",
    "#! aws s3 ls s3://rapid7-opendata/fdns/any/v1/date=202005/ --no-sign-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Lambda fully into Jupyter notebook\n",
    "# To-do: Codify the creation of a S3 bucket to save the Athena results\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# The core functions notebook contains generalized functions that apply across use cases\n",
    "%run ./corefunctions.ipynb\n",
    "\n",
    "# Make sure to update these values\n",
    "DOMAIN_TO_QUERY = 'microsoft.com' # This should look like 'domain.com'. The wildcard will be added automatically later.\n",
    "ATHENA_BUCKET = 's3://brevity-athena' # This will need to be customized and specific to your own account (i.e. s3://customname-athena').\n",
    "ATHENA_DB = 'rapid7fdns' # This should align with the database and not need changed if it was created using the previous queries.\n",
    "ATHENA_TABLE = 'rapid7_fdns_any' # This should align with the table and not need changed if it was created using the previous queries.\n",
    "\n",
    "# Do not modify this query unless the intent is to customize\n",
    "querydomain = '%.' + DOMAIN_TO_QUERY\n",
    "query = \"SELECT * FROM %s WHERE name LIKE '%s' AND date = (SELECT MAX(date) from %s);\" % (ATHENA_TABLE,querydomain,ATHENA_TABLE)\n",
    "\n",
    "execid = queryathena(ATHENA_DB, ATHENA_BUCKET, query)\n",
    "print(execid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the Lambda fully into Jupyter notebook\n",
    "# This code is taken again from Evan Perotti from http://securityriskadvisors.com/blog/creating-a-project-sonar-fdns-api-with-aws/ and was adapted from the Lambda.\n",
    "# Retrieve results Lambda\n",
    "\n",
    "import json, boto3, time, requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Load an external notebook with normalized functions\n",
    "%run ./corefunctions.ipynb\n",
    "\n",
    "# Utilize executionID to retrieve results\n",
    "downloadURL = retrieveresults(execid)\n",
    "\n",
    "# Load output into dataframe\n",
    "s=requests.get(downloadURL).content\n",
    "dfhosts=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "dfhosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an external notebook with normalized functions\n",
    "%run ./corefunctions.ipynb\n",
    "# Pass the central function the dataframe and the column containing the IP address\n",
    "df_min = get_location(dfhosts, 'value')\n",
    "df_min.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an external notebook with normalized functions\n",
    "%run ./corefunctions.ipynb\n",
    "df_plot = prepare_location(df_min)\n",
    "df_plot.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The map depicted in this command requires the following two extensions to be enabled. These need to be run as Lifecycle rules if you are using SageMaker.\n",
    "#!jupyter nbextension enable --py gmaps\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "%run ./corefunctions.ipynb\n",
    "fig = get_heatmap(df_plot)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
