{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Straylight\n",
    "\n",
    "### Forward DNS Reconnaissance and Attack Surface Visualization using Rapid7 Sonar dataset\n",
    "\n",
    "__Introduction:__\n",
    "This walkthrough provides the steps to configure AWS cloud based resources to query the Forward DNS stored in the Rapid 7 Project Sonar public dataset. The output of this process can be used to supplement passive domain reconnaissance techniques. It can also be integrated as a fully automated and entirely passive process to track attack surface on a monthly basis.\n",
    "\n",
    "This notebook will take a domain name (i.e. microsoft.com) as input and query the project Sonar public dataset for the applicable Forward DNS entries. Additionally, it processes the results by geomapping the IP addresses and producing a heatmap of the global external presence of the domain.\n",
    "\n",
    "The results provide a completely passive method for reconnaisance and mapping of domains without any direct interaction, querying, or brute-forcing of a domain.\n",
    "\n",
    "__GitHub:__\n",
    "* https://github.com/brevityinmotion/straylight\n",
    "\n",
    "__Blog:__\n",
    "* [External IP Domain Reconnaissance and Attack Surface Visualization in Under 2 Minutes](https://medium.com/@brevityinmotion/external-ip-domain-reconnaissance-and-attack-surface-visualization-in-under-2-minutes-b2ab06105def?sk=45a029919647bd3214e6dd1e8526ca25)\n",
    "\n",
    "__Credits:__\n",
    "* Special thank you to Evan Perotti for the awesome walkthrough for querying project Sonar FDNS and the query code within the Lambda APIs! Some of the ideas and steps were adapted from Evan's tutorial at: http://securityriskadvisors.com/blog/creating-a-project-sonar-fdns-api-with-aws/\n",
    "* Thank you to Rapid7 for the availability of this valuable dataset (https://www.rapid7.com/research/project-sonar/) and the blog post detailing how to build and query the dataset (https://blog.rapid7.com/2018/10/16/how-to-conduct-dns-reconnaissance-for-02-using-rapid7-open-data-and-aws/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Dependencies\n",
    "For this notebook to work, AWS Athena needs to be manually configured using the following setup information. The queries and approach are from Rapid 7's blog detailing the process (https://blog.rapid7.com/2018/10/16/how-to-conduct-dns-reconnaissance-for-02-using-rapid7-open-data-and-aws/).\n",
    "\n",
    "The query code is also located in a [Brevity In Motion gist](https://gist.github.com/brevityinmotion/af6f10257c6d7a9fe175e30a5af3d45c).\n",
    "\n",
    "### Additional Notebooks\n",
    "The code in this notebook utilizes code within the following additional notebooks. Each notebook needs to reside in the same directory as this current notebook for it to run.\n",
    "* configuration.ipynb\n",
    "* corefunctions.ipynb\n",
    "* tools-maxmind.ipynb\n",
    "\n",
    "### AWS Athena\n",
    "Within the AWS Athena console, you will need to run the following three queries to configure the environment.\n",
    "TODO: Codify these commands into Boto3 commands to run directly from the notebook.\n",
    "\n",
    "#### Query 1:\n",
    "<code>CREATE DATABASE rapid7fdns;</code>\n",
    "\n",
    "#### Query 2:\n",
    "<code>CREATE EXTERNAL TABLE IF NOT EXISTS rapid7_fdns_any (\n",
    "  `timestamp` timestamp,\n",
    "  `name` string,\n",
    "  `type` string,\n",
    "  `value` string \n",
    ") PARTITIONED BY (\n",
    "  date string \n",
    ")\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
    "WITH SERDEPROPERTIES (\n",
    "  'serialization.format' = '1'\n",
    ") LOCATION 's3://rapid7-opendata/fdns/any/v1/'\n",
    "TBLPROPERTIES ('has_encrypted_data'='false');\n",
    "</code>\n",
    "#### Query 3:\n",
    "<code>msck repair table rapid7_fdns_any;</code>\n",
    "\n",
    "### AWS IAM Roles\n",
    "When the initial SageMaker instance is created, it will create an execution role providing the relevant access to the Notebooks running within SageMaker. There will be base permissions, but will need extended to other services that the notebooks utilize. The following services need to be added:\n",
    "* AWS S3 -  Get and Put access to buckets for processed and results data including the location where the Athena query results are stored.\n",
    "* AWS Secrets Manager - This should be part of the default policy, but has a conditional limitation to only secrets with the format of SageMaker-*.\n",
    "* AWS Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the core configurations notebook. This generally only needs to be run once.\n",
    "%run ./configuration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies for tools-r7sonar from the configuration.ipynb notebook\n",
    "dependencies_r7sonar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The core functions notebook contains generalized functions that apply across use cases\n",
    "%run ./corefunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Maxmind notebook has the configuration functions to download the maxmind databases and csvs\n",
    "%run ./tools-maxmind.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish additional imports\n",
    "import json, boto3, os, requests, io, time, logging\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the maxmind dependencies\n",
    "secret_name = 'AmazonSageMaker-geoip'\n",
    "region_name = 'us-east-1'\n",
    "license_key = get_secret(secret_name, region_name)\n",
    "# The return value of the function contains the {secretname:secretvalue}. To only utilize the secret, the secretname can be referenced as depicted below.\n",
    "licensesecret = license_key['license_key']\n",
    "\n",
    "# This function is located in the tools-maxmind.ipynb notebook\n",
    "maxmind_geolitecity_db(licensesecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to update these values\n",
    "DOMAIN_TO_QUERY = 'microsoft.com' # This should look like 'domain.com'. The wildcard will be added automatically later.\n",
    "ATHENA_BUCKET = 's3://brevity-athena' # This will need to be customized and specific to your own account (i.e. s3://customname-athena').\n",
    "ATHENA_DB = 'rapid7fdns' # This should align with the database and not need changed if it was created using the previous queries.\n",
    "ATHENA_TABLE = 'rapid7_fdns_any' # This should align with the table and not need changed if it was created using the previous queries.\n",
    "\n",
    "# Do not modify this query unless the intent is to customize\n",
    "querydomain = '%.' + DOMAIN_TO_QUERY\n",
    "query = \"SELECT * FROM %s WHERE name LIKE '%s' AND date = (SELECT MAX(date) from %s);\" % (ATHENA_TABLE,querydomain,ATHENA_TABLE)\n",
    "\n",
    "execid = queryathena(ATHENA_DB, ATHENA_BUCKET, query)\n",
    "print(execid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize executionID to retrieve results\n",
    "# The retrieveresults function is in the corefunctions.ipynb notebook\n",
    "downloadURL = retrieveresults(execid)\n",
    "\n",
    "# Load output into dataframe\n",
    "s=requests.get(downloadURL).content\n",
    "dfhosts=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "dfhosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the central function the dataframe and the column containing the IP address\n",
    "# The get_location function is in the corefunctions.ipynb notebook\n",
    "df_min = get_location(dfhosts, 'value')\n",
    "df_min.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output results to excel spreadsheet\n",
    "# Example code to output the dataframe. This file is not further utilized in this notebook.\n",
    "df_min.to_excel(\"sonar-domains.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an external notebook with normalized functions\n",
    "# The prepare_location function is in the corefunctions.ipynb notebook\n",
    "df_plot = prepare_location(df_min)\n",
    "df_plot.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The map depicted in this command requires the following two extensions to be enabled. These need to be run as Lifecycle rules if you are using SageMaker.\n",
    "# The gist for the lifecycle code is at: https://gist.github.com/brevityinmotion/495d1b77bd3f3ea679ef7ccfddce23b3\n",
    "\n",
    "#!jupyter nbextension enable --py gmaps\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "# The get_heatmap function is in the corefunctions.ipynb notebook\n",
    "fig = get_heatmap(df_plot)\n",
    "embed_minimal_html('sonar-heatmap.html', views=[fig]) # Export the map to html\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the following to upload the results to a static S3 hosting bucket for interactive viewing\n",
    "#bucket = 'recon.brevityinmotion.com'\n",
    "#file_name = 'sonar-heatmap.html'\n",
    "\n",
    "# The upload_file function is in the corefunctions.ipynb notebook\n",
    "#upload_file(file_name,bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not necessary to run but are helpful S3 queries to check for latest datasets\n",
    "#! aws s3 ls s3://rapid7-opendata/fdns/any/v1/ --no-sign-request\n",
    "#! aws s3 ls s3://rapid7-opendata/fdns/any/v1/date=202005/ --no-sign-request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
