{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This accelerator provides a function to retrieve a secret value from AWS secrets manager. The secret name along with the region must be passed into the function as parameters. The code has been adapted into a parameterized function from the canned template provided by AWS.\n",
    "import json, boto3, time, requests, io, base64\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_secret(secret_name, region_name):\n",
    "\n",
    "    #secret_name = \"AmazonSageMaker-gmaps\"\n",
    "    #region_name = \"us-east-2\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            secret = get_secret_value_response['SecretString']\n",
    "            #secret = json.loads(secret)\n",
    "            return json.loads(secret)\n",
    "        else:\n",
    "            decoded_binary_secret = base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "            return json.loads(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This accelerator provides a standardized pattern for retrieving Athena query results based on the execution id.\n",
    "# This code is adapted from Evan Perotti from http://securityriskadvisors.com/blog/creating-a-project-sonar-fdns-api-with-aws/ and was adapted from the Lambda.\n",
    "\n",
    "def retrieveresults(execid):\n",
    "    athena = boto3.client('athena')\n",
    "    s3 = boto3.client('s3')\n",
    "    queryres = athena.get_query_execution(\n",
    "        QueryExecutionId = execid\n",
    "    )\n",
    "    \n",
    "    # Athena query checking code is from https://medium.com/dataseries/automating-athena-queries-from-s3-with-python-and-save-it-as-csv-8917258b1045\n",
    "    # Loop until results are ready or fail after 5 minutes\n",
    "    status = 'RUNNING'\n",
    "    iterations = 60\n",
    "    \n",
    "    while (iterations>0):\n",
    "        iterations = iterations - 1\n",
    "        response_get_query_details = athena.get_query_execution(\n",
    "        QueryExecutionId = execid\n",
    "        )\n",
    "        status = response_get_query_details['QueryExecution']['Status']['State']\n",
    "        print(status)\n",
    "        if (status == 'FAILED') or (status == 'CANCELLED'):\n",
    "            return False, False\n",
    "        elif status == 'SUCCEEDED':\n",
    "            try:\n",
    "                outputloc = queryres['QueryExecution']['ResultConfiguration']['OutputLocation']\n",
    "                full = outputloc[5:] # trim s3:// prefix\n",
    "                bucketloc = full.split('/')[0] # get bucket from full path\n",
    "                keyloc = full.replace(bucketloc,'')[1:] # get key and remove starting /\n",
    "    \n",
    "                url = s3.generate_presigned_url(\n",
    "                    'get_object',\n",
    "                    Params={\n",
    "                    'Bucket':bucketloc,\n",
    "                    'Key':keyloc\n",
    "                    }\n",
    "                )\n",
    "                return url\n",
    "            except:\n",
    "                url = \"No results\"\n",
    "                return url\n",
    "        else:\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This accelerator provides a standardized function for passing queries to Athena.\n",
    "\n",
    "def queryathena(athenadb, athenabucket, query):\n",
    "    athena = boto3.client('athena')\n",
    "    qexec = athena.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database':athenadb\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation':athenabucket\n",
    "        }\n",
    "    )\n",
    "    execid = qexec['QueryExecutionId']\n",
    "    return execid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare GoogleMaps API integration\n",
    "\n",
    "# pip install gmaps\n",
    "#https://jupyter-gmaps.readthedocs.io/en/latest/tutorial.html\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "def prepare_location(df_min):\n",
    "    #pandas chaining\n",
    "    #1 - group by lat/long\n",
    "    #2 - get the size of a column to consolidate groupby object\n",
    "    #3 - take it from a indexed series to a dataframe\n",
    "    #4 - reset the index so that groupby is flattened and can be referenced\n",
    "    #5 - rename the size column (0) to 'count'\n",
    "    df_plot = df_min.groupby(['latitude', 'longitude']).size().to_frame().reset_index().rename(columns={0:'count'})\n",
    "    return df_plot\n",
    "\n",
    "# Need to enable extensions and widgets before figure will display\n",
    "#jupyter nbextension enable --py gmaps\n",
    "#jupyter nbextension enable --py widgetsnbextension\n",
    "#Restart Jupyter\n",
    "\n",
    "def get_heatmap(df_plot):\n",
    "    locations = df_plot[['latitude', 'longitude']]\n",
    "    weights = df_plot['count']\n",
    "    secretname = 'AmazonSageMaker-gmaps'\n",
    "    region_name = 'us-east-1'\n",
    "    api = get_secret(secretname, region_name)\n",
    "    apisecret = api['gmapsapi']\n",
    "    gmaps.configure(api_key=apisecret)\n",
    "    fig = gmaps.figure()\n",
    "    #fig.add_layer(gmaps.heatmap_layer(locations, weights=weights))\n",
    "    fig.add_layer(gmaps.heatmap_layer(locations))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency to have 'pip install geoip' installed from configuration notebook.\n",
    "import geoip2.database\n",
    "reader = geoip2.database.Reader('tools/GeoLite2-City.mmdb')\n",
    "\n",
    "#create a function to find the lat/long of the addy based on maxmind reader\n",
    "def lookup_location(IPAddress):\n",
    "    try:\n",
    "        response = reader.city(IPAddress)\n",
    "        # TO-DO - investigate return variables. May be a mismatch with state and city.\n",
    "        return round(response.location.latitude,3), round(response.location.longitude,3), response.country.name, response.city.name\n",
    "    except:\n",
    "        # If private IP address, return address at center of map\n",
    "        return 0,0,0,0\n",
    "        #return null\n",
    "\n",
    "#function to get a dual output into different columns in a dataframe\n",
    "#https://stackoverflow.com/questions/23690284/pandas-apply-function-that-returns-multiple-values-to-rows-in-pandas-dataframe\n",
    "def apply_and_concat(dataframe, field, func, column_names):\n",
    "    return pd.concat((\n",
    "                         dataframe,\n",
    "                         dataframe[field].apply(\n",
    "                         lambda cell: pd.Series(func(cell), index=column_names))), axis=1)\n",
    "\n",
    "def get_location(df_ip,columnIP):\n",
    "    df_min = apply_and_concat(df_ip, columnIP, lookup_location, ['latitude', 'longitude', 'country', 'locality'])\n",
    "    # Remove the rows with missing lat/long\n",
    "    df_min = df_min[(df_min.latitude != 0.000)&(df_min.longitude != 0.000)]\n",
    "    return df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure SNS topic and text messaging\n",
    "def notify_user(phonenumber,message):\n",
    "    import boto3\n",
    "    client = boto3.client('sns')\n",
    "    client.publish(PhoneNumber=phonenumber, Message=message)\n",
    "\n",
    "# Example function call syntax\n",
    "# notify_user('+1XXXXXXXXXX', 'Results are done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload files to S3\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
